{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "253pfoAX69K5"
      },
      "source": [
        "# Advanced CNN Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZalQgckhN4s"
      },
      "source": [
        "## Scenes Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUGH96MUrqeD"
      },
      "source": [
        "## 1.Tải bộ dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRA-SQfT4j2i",
        "outputId": "c94e55a3-64b6-4db8-e77d-0261c491f3c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 3] The system cannot find the path specified: '/content/drive/MyDrive/Colab Notebooks/MODULE06/W02'\n",
            "g:\\AIO\\EXERCISE\\AIO-2024\\MODULE06\\WEEK02\n"
          ]
        }
      ],
      "source": [
        "# bộ dữ liệu mg_cls_scenes_classification.zip\n",
        "# https://drive.google.com/file/d/1ZUCuYDOe4VVbZvNVZovpquaRQqqJQ639/view?usp=drive_link\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/MODULE06/W02\n",
        "# !gdow 1ZUCuYDOe4VVbZvNVZovpquaRQqqJQ639"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J3diVQ2scFc"
      },
      "source": [
        "## 2.Import các thư viện cần thiết"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rDA-JvSRsZ71"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JQ0kPL0ss7b"
      },
      "source": [
        "## 3.Cố định giá trị ngẫu nhiên\n",
        "Để có thể tái tạo lại cùng một kết quả mô hình, chúng ta sẽ cố định cùng một giá trị ngẫu nhiên (seed) cho các thư viện có chứa các hàm tạo giá trị ngẫu nhiên"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WS7HkaLbsHia"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed = 59\n",
        "set_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu4v0RvZuamO"
      },
      "source": [
        "## 4.Đọc dữ liệu\n",
        "Để thuận tiện trong việc xây dựng PyTorch datasets, chúng ta sẽ ghi nhận thông tin về các classes, đường dẫn đến tất cả các ảnh cũng như label tương ứng như sau."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PtIv3RGPwGTH",
        "outputId": "5c7ec4c6-eeb2-459d-98f8-8b6ebea494cc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/MODULE06/W02'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eW1czNAsZ4z"
      },
      "outputs": [],
      "source": [
        "root_dir = 'Data/scenes_classification'\n",
        "train_dir = os.path.join(root_dir, 'train')\n",
        "test_dir = os.path.join(root_dir, 'val')\n",
        "classes = {label_idx:class_name for label_idx, class_name in enumerate(sorted(os.listdir(train_dir)))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuAMn4StsZ2O",
        "outputId": "4b3487ab-9d37-47e1-a767-8982afe614f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(dict_keys([0, 1, 2, 3, 4, 5]),\n",
              " dict_values(['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes.keys(), classes.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh_Q-cT7sZzi",
        "outputId": "45dff549-f9d1-4aa5-b523-7a9cf6ba7971"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'buildings',\n",
              " 1: 'forest',\n",
              " 2: 'glacier',\n",
              " 3: 'mountain',\n",
              " 4: 'sea',\n",
              " 5: 'street'}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbpLlrFn4cmR"
      },
      "outputs": [],
      "source": [
        "# Đọc lên toàn bộ các đường dẫn ảnh cũng như label tương ứng. Tuy nhiên, ta sẽ coi thư mục val là tập test của bộ dữ liệu và sẽ khai báo danh sách riêng cho bộ này\n",
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "for dataset_path in [train_dir, test_dir]:\n",
        "  for label_idx, class_name in classes.items():\n",
        "    class_dir = os.path.join(dataset_path, class_name)\n",
        "    for img_filename in os.listdir(class_dir):\n",
        "      img_path = os.path.join(class_dir, img_filename)\n",
        "      if 'train' in dataset_path:\n",
        "        X_train.append(img_path)\n",
        "        y_train.append(label_idx)\n",
        "      else:\n",
        "        X_test.append(img_path)\n",
        "        y_test.append(label_idx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0WICJy_5HF-",
        "outputId": "5ac2674c-4782-42da-ffea-6b1efbbb2141"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14034, 14034, 3000, 3000)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laFJaf080ZVp",
        "outputId": "4077d79a-a2ed-411b-aab4-35e86cda2134"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[:10], y_test[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NzqRduj5hw-",
        "outputId": "487b0087-ebf1-463f-9c5d-31d85b7b698b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['Data/scenes_classification/train/buildings/19447.jpg',\n",
              "  'Data/scenes_classification/train/buildings/19460.jpg',\n",
              "  'Data/scenes_classification/train/buildings/19440.jpg',\n",
              "  'Data/scenes_classification/train/buildings/19526.jpg',\n",
              "  'Data/scenes_classification/train/buildings/19513.jpg',\n",
              "  'Data/scenes_classification/train/buildings/1964.jpg',\n",
              "  'Data/scenes_classification/train/buildings/19416.jpg',\n",
              "  'Data/scenes_classification/train/buildings/1943.jpg',\n",
              "  'Data/scenes_classification/train/buildings/1954.jpg',\n",
              "  'Data/scenes_classification/train/buildings/19556.jpg'],\n",
              " ['Data/scenes_classification/val/buildings/20078.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20207.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20057.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20083.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20113.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20073.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20186.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20060.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20131.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20094.jpg'])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[:10], X_test[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MayuA9HM0tD9"
      },
      "source": [
        "## 5.Chia bộ dữ liệu train, val, test\n",
        "Vì đã có sẵn bộ dữ liệu train và test, ta chỉ việc\n",
        "chia thêm cho tập val từ tập train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqWpOymjsZpK"
      },
      "outputs": [],
      "source": [
        "seed = 0\n",
        "val_size = 0.2\n",
        "is_shuffle = True\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, random_state=seed, shuffle=is_shuffle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvQd6LvZsZmv",
        "outputId": "5fcc1768-39ee-4ab9-bb63-31a998220c59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11227, 2807, 3000)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train), len(X_val), len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrpfYTUOsZkI",
        "outputId": "2faaf53b-9e99-41de-ac30-32bc17be7245"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['Data/scenes_classification/train/buildings/11523.jpg',\n",
              "  'Data/scenes_classification/train/glacier/15501.jpg',\n",
              "  'Data/scenes_classification/train/glacier/1910.jpg',\n",
              "  'Data/scenes_classification/train/forest/11068.jpg',\n",
              "  'Data/scenes_classification/train/sea/8062.jpg',\n",
              "  'Data/scenes_classification/train/mountain/7226.jpg',\n",
              "  'Data/scenes_classification/train/mountain/10323.jpg',\n",
              "  'Data/scenes_classification/train/mountain/7113.jpg',\n",
              "  'Data/scenes_classification/train/glacier/7502.jpg',\n",
              "  'Data/scenes_classification/train/street/18005.jpg'],\n",
              " ['Data/scenes_classification/train/glacier/19920.jpg',\n",
              "  'Data/scenes_classification/train/buildings/16692.jpg',\n",
              "  'Data/scenes_classification/train/street/10729.jpg',\n",
              "  'Data/scenes_classification/train/street/3298.jpg',\n",
              "  'Data/scenes_classification/train/mountain/10666.jpg',\n",
              "  'Data/scenes_classification/train/sea/7233.jpg',\n",
              "  'Data/scenes_classification/train/glacier/19197.jpg',\n",
              "  'Data/scenes_classification/train/forest/18907.jpg',\n",
              "  'Data/scenes_classification/train/glacier/4892.jpg',\n",
              "  'Data/scenes_classification/train/mountain/4980.jpg'],\n",
              " ['Data/scenes_classification/val/buildings/20078.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20207.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20057.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20083.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20113.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20073.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20186.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20060.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20131.jpg',\n",
              "  'Data/scenes_classification/val/buildings/20094.jpg'])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[:10], X_val[:10], X_test[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLuWgeq72MNQ"
      },
      "source": [
        "## 6.Xây dựng class pytorch datasets\n",
        "xây dựng pytorch dataset cho bộ dữ liệu Scenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgIXIVH-sZhQ"
      },
      "outputs": [],
      "source": [
        "class ScenesDataset(Dataset):\n",
        "  def __init__(self, X, y, transform=None):\n",
        "    self.transform = transform\n",
        "    self.img_paths = X\n",
        "    self.labels = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = self.img_paths[idx]\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "\n",
        "    return img, self.labels[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thPybWuJ3IPQ"
      },
      "source": [
        "## 7.Xây dựng hàm tiền xử lý ảnh (transform)\n",
        "Để đảm bảo dữ liệu ảnh đầu vào được đồng bộ về kích thước và giá trị, chúng ta tự định nghĩa hàm transform để tiền xử lý ảnh đầu vào như sau (không sử dụng thư viện torchvision.transforms). Các kỹ thuật được áp dụng: resize ảnh, đổi về tensor và chuẩn hóa giá trị pixel về khoảng (0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WQJyyRN3H9H"
      },
      "outputs": [],
      "source": [
        "def transform (img, img_size =(224, 224)):\n",
        "  img = img.resize(img_size)\n",
        "  img = np.array(img)[... , :3]\n",
        "  img = torch.tensor(img).permute(2, 0, 1).float()\n",
        "  normalized_img = img/255.0\n",
        "\n",
        "  return normalized_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb0zmz7Q8dAv"
      },
      "source": [
        "## 8.Khai báo datasets object cho ba bộ train, val, test\n",
        "khai báo ba object datasets tương ứng cho ba bộ dữ liệu train, val, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl2b9y2t3H5T"
      },
      "outputs": [],
      "source": [
        "train_dataset = ScenesDataset(X_train, y_train,transform=transform)\n",
        "val_dataset = ScenesDataset(X_val, y_val,transform=transform)\n",
        "test_dataset = ScenesDataset(X_test, y_test,transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT-S1kEC3H1x",
        "outputId": "12ec0b29-7e10-4eee-c229-95d6531895ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11227, 2807, 3000)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset), len(val_dataset), len(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaU-JmWx9E0N"
      },
      "source": [
        "## 9.Khai báo dataloader\n",
        "Với ba object datasets trên, ta khai báo giá trị batch size và\n",
        "tạo dataloader như sau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KIQPdIh3Hwf"
      },
      "outputs": [],
      "source": [
        "train_batch_size = 64\n",
        "test_batch_size = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=test_batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Dd1gvKS3Hte",
        "outputId": "25609090-d237-49a7-c733-3d1efdf5e536"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7d4be26a9de0>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCvNhwFd9iHA"
      },
      "source": [
        "## 10.Xây dựng model\n",
        "xây dựng class cho model deep learning với kiến trúc DenseNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQPojEjP3Hqs"
      },
      "outputs": [],
      "source": [
        "#xây dựng class Dense Block, đây là một thành phần đặc biệt của kiến trúc DenseNet\n",
        "class BottleneckBlock (nn.Module):\n",
        "  def __init__(self, in_channels, growth_rate):\n",
        "    super(BottleneckBlock, self).__init__()\n",
        "    self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "    self.conv1 = nn.Conv2d(in_channels, 4*growth_rate, kernel_size=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(4*growth_rate)\n",
        "    self.conv2 = nn.Conv2d(4*growth_rate, growth_rate,kernel_size=3, padding=1, bias=False)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    res = x.clone().detach()\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = torch.cat([res, x], 1)\n",
        "\n",
        "    return x\n",
        "\n",
        "class DenseBlock(nn.Module):\n",
        "  def __init__(self, num_layers, in_channels, growth_rate):\n",
        "    super(DenseBlock, self).__init__()\n",
        "    layers = []\n",
        "    for i in range(num_layers):\n",
        "      layers.append(BottleneckBlock(in_channels + i*growth_rate, growth_rate))\n",
        "\n",
        "    self.block = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.block(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mFUDgje3Hn0"
      },
      "outputs": [],
      "source": [
        "#Với DenseBlock, ta triển khai toàn bộ kiến trúc DenseNet\n",
        "class DenseNet(nn.Module):\n",
        "  def __init__(self, num_blocks, growth_rate, num_classes):\n",
        "    super(DenseNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 2*growth_rate, kernel_size=7, padding=3, stride=2, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(2*growth_rate)\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.dense_blocks = nn.ModuleList()\n",
        "    in_channels = 2*growth_rate\n",
        "\n",
        "    for i, num_layers in enumerate(num_blocks):\n",
        "      self.dense_blocks.append(DenseBlock(num_layers, in_channels, growth_rate))\n",
        "      in_channels += num_layers*growth_rate\n",
        "      if i != len(num_blocks) - 1:\n",
        "        out_channels = in_channels//2\n",
        "        self.dense_blocks.append(nn.Sequential(\n",
        "                                              nn.BatchNorm2d(in_channels),\n",
        "                                              nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
        "                                              nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "                                              ))\n",
        "        in_channels = out_channels\n",
        "\n",
        "    self.bn2 = nn.BatchNorm2d(in_channels)\n",
        "    self.pool2 = nn.AvgPool2d(kernel_size=7)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc = nn.Linear(in_channels,num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool1(x)\n",
        "\n",
        "    for block in self.dense_blocks:\n",
        "      x = block(x)\n",
        "\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool2(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x #self.block(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oT4FCoF4sZXF"
      },
      "outputs": [],
      "source": [
        "#khai báo model DenseNet\n",
        "n_classes = len(list(classes.keys()))\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = DenseNet([6, 12, 24, 16], growth_rate=32, num_classes=n_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RzbGY66ICIk3",
        "outputId": "16048c17-f2fe-458f-dbc6-d550bf923a74"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd28e_WwCIfs",
        "outputId": "51385f25-179b-438c-dda6-815f11fd8576"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGbqteKhCXjU"
      },
      "source": [
        "## 11.Khai báo hàm loss và thuật toán huấn luyện\n",
        "sử dụng hàm loss CrossEntropy và Stochastic Gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhmmITVCA5z2"
      },
      "outputs": [],
      "source": [
        "lr = 1e-2\n",
        "epochs = 15\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtwGXDOoCIZb"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion, device):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  losses = []\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in dataloader:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      losses.append(loss.item())\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "      loss = sum(losses)/len(losses)\n",
        "      acc = correct/total\n",
        "  return loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRZ8UtUxCIWC"
      },
      "outputs": [],
      "source": [
        "def fit(model, train_loader, val_loader, criterion, optimizer, device, epochs):\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  for epoch in range(epochs):\n",
        "    batch_train_losses = []\n",
        "\n",
        "    model.train()\n",
        "    for idx, (inputs, labels) in enumerate(train_loader):\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      batch_train_losses.append(loss.item())\n",
        "\n",
        "    train_loss = sum(batch_train_losses)/len(batch_train_losses)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print (f'EPOCH{epoch+1}:\\tTrain loss:{train_loss:.4f}\\tVal loss:{val_loss:.4f}')\n",
        "\n",
        "  return train_losses , val_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ1myx5fDg0P"
      },
      "source": [
        "## 12.Xây dựng hàm huấn luyện model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4sBQYKsjHsc8",
        "outputId": "77bd4b8e-879a-4220-cce7-e1d2a3431283"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DenseNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (dense_blocks): ModuleList(\n",
              "    (0): DenseBlock(\n",
              "      (block): Sequential(\n",
              "        (0): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (3): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (4): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (5): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (2): DenseBlock(\n",
              "      (block): Sequential(\n",
              "        (0): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (3): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (4): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (5): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (6): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (7): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (8): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (9): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (10): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (11): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (4): DenseBlock(\n",
              "      (block): Sequential(\n",
              "        (0): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (3): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (4): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (5): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (6): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (7): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (8): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (9): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (10): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (11): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (12): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (13): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (14): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (15): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (16): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (17): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (18): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (19): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (20): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (21): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (22): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (23): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (6): DenseBlock(\n",
              "      (block): Sequential(\n",
              "        (0): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (3): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (4): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (5): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (6): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (7): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (8): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (9): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (10): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (11): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (12): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (13): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (14): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (15): BottleneckBlock(\n",
              "          (bn1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool2): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
              "  (relu): ReLU()\n",
              "  (fc): Linear(in_features=1024, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEw6RQWTH-EZ",
        "outputId": "f308c0ca-18d7-45bd-dfb3-3214fb391d28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7d4be26a9de0>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7d4be26a9bd0>,\n",
              " CrossEntropyLoss(),\n",
              " SGD (\n",
              " Parameter Group 0\n",
              "     dampening: 0\n",
              "     differentiable: False\n",
              "     foreach: None\n",
              "     fused: None\n",
              "     lr: 0.01\n",
              "     maximize: False\n",
              "     momentum: 0\n",
              "     nesterov: False\n",
              "     weight_decay: 0\n",
              " ),\n",
              " 'cuda',\n",
              " 15)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_loader, val_loader, criterion, optimizer, device, epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZqHaOfoBGEJ"
      },
      "outputs": [],
      "source": [
        "train_losses, val_losses = fit(model, train_loader, val_loader, criterion, optimizer, device, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RdToX43FpB9"
      },
      "source": [
        "## 13.Đánh giá model\n",
        "Ta gọi hàm evaluate() để đánh giá performance của model trên\n",
        "hai tập val và test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qRCPabSCIQS"
      },
      "outputs": [],
      "source": [
        "val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "print('Evaluation on val/ test dataset')\n",
        "print('Val accuracy:', val_acc)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUPqd_xi0QTN"
      },
      "outputs": [],
      "source": [
        "#  trực quan kết quả huấn luyện trên tập train và val cho bài toán nonlinear data classification\n",
        "fig , ax = plt.subplots(1, 2, figsize=(12, 10))\n",
        "\n",
        "ax[0, 0].plot(train_losses, color='green')\n",
        "ax[0, 0].set(xlabel='Epoch', ylabel='Loss')\n",
        "ax[0, 0].set_title('Training Loss')\n",
        "\n",
        "ax [0, 1].plot(val_losses, color='orange')\n",
        "ax [0, 1].set(xlabel='Epoch', ylabel='Loss')\n",
        "ax [0, 1].set_title('Validation Loss')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yR8qhQjHF-2B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZOrIRD5F-zA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XqNnCLeF-vr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd_c8RpEF-s3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dg94TjpmF-p3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l5DOMER65_z"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
