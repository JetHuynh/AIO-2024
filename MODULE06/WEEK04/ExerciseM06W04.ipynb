{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b7cb5e90f1064e65a9acadb3342c36a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97085b06fc784acab5a3b446d9876326",
              "IPY_MODEL_0303ea5d59a7478c95317653224eccd2",
              "IPY_MODEL_8e276915b185416c86807f613422191a"
            ],
            "layout": "IPY_MODEL_da815355fd5c4a22bbd492e14db8dca4"
          }
        },
        "97085b06fc784acab5a3b446d9876326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54982841d9cd4407bfe8538aad37b25e",
            "placeholder": "​",
            "style": "IPY_MODEL_93a4d3ab1a06433f8569c09ffd338db3",
            "value": "model.safetensors: 100%"
          }
        },
        "0303ea5d59a7478c95317653224eccd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35863770a03948619de1cebd7ea483bc",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac428d8b68a94bdcb9c7cfdd5109cd67",
            "value": 267954768
          }
        },
        "8e276915b185416c86807f613422191a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_929964ab7e3e4845838662d09e0346b3",
            "placeholder": "​",
            "style": "IPY_MODEL_ddb70ed778594d9a93d83805bee8cd2c",
            "value": " 268M/268M [00:04&lt;00:00, 93.9MB/s]"
          }
        },
        "da815355fd5c4a22bbd492e14db8dca4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54982841d9cd4407bfe8538aad37b25e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93a4d3ab1a06433f8569c09ffd338db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35863770a03948619de1cebd7ea483bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac428d8b68a94bdcb9c7cfdd5109cd67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "929964ab7e3e4845838662d09e0346b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb70ed778594d9a93d83805bee8cd2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "477813d3da8e45c5a2514230bf955752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_657ea2845d624514a2acff5efb9d516d",
              "IPY_MODEL_1c8fef96716e4d7eb492291da4cb2a04",
              "IPY_MODEL_bd5d4cdc170240f09f38e8470701b2c4"
            ],
            "layout": "IPY_MODEL_24b022b8a25d4c55aaf7b9822ef27f6e"
          }
        },
        "657ea2845d624514a2acff5efb9d516d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_109fb11dd61f417eb3e5abd220b38f4f",
            "placeholder": "​",
            "style": "IPY_MODEL_2b8e9f73847a4f61abcd9dd2bca7269a",
            "value": "Downloading builder script: 100%"
          }
        },
        "1c8fef96716e4d7eb492291da4cb2a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_190b242c08dc4e45830af30b2ef2c80c",
            "max": 4203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcef230c45054ba6aaa444703037b770",
            "value": 4203
          }
        },
        "bd5d4cdc170240f09f38e8470701b2c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fed5a54412fb457db25405d32293fc93",
            "placeholder": "​",
            "style": "IPY_MODEL_adbab2ade3e44465afed6e370dc12707",
            "value": " 4.20k/4.20k [00:00&lt;00:00, 92.2kB/s]"
          }
        },
        "24b022b8a25d4c55aaf7b9822ef27f6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "109fb11dd61f417eb3e5abd220b38f4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b8e9f73847a4f61abcd9dd2bca7269a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "190b242c08dc4e45830af30b2ef2c80c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcef230c45054ba6aaa444703037b770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fed5a54412fb457db25405d32293fc93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adbab2ade3e44465afed6e370dc12707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Phần 1. Transformer"
      ],
      "metadata": {
        "id": "8cqTOpCKRPtb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1. Kiến trúc Transformer"
      ],
      "metadata": {
        "id": "ayIT4CKvRF5j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Input Embedding, Positional Encoding"
      ],
      "metadata": {
        "id": "KbjlacreRYjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # import the torch module\n",
        "import torch.nn as nn # import the necessary module"
      ],
      "metadata": {
        "id": "47NsGuVeYS94"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aKHXPs4yOdl8"
      },
      "outputs": [],
      "source": [
        "class TokenAndPositionEmbedding(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, max_length, device='cpu'):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "    self.word_emb = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n",
        "    self.pos_emb = nn.Embedding(num_embeddings=max_length, embedding_dim=embed_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    N, seq_len = x.size()\n",
        "    positions = torch.arange(0, seq_len).expand(N, seq_len).to(self.device)\n",
        "    output1 = self.word_emb(x)\n",
        "    output2 = self.pos_emb(positions)\n",
        "    output = output1+output2\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Encoder"
      ],
      "metadata": {
        "id": "0Hx6vykZRfbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(nn.Module):\n",
        "  def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.attn = nn.MultiheadAttention(\n",
        "        embed_dim=embed_dim,\n",
        "        num_heads=num_heads,\n",
        "        batch_first=True)\n",
        "\n",
        "    self.ffn = nn.Sequential(\n",
        "        nn.Linear(in_features=embed_dim, out_features=ff_dim, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=ff_dim, out_features=embed_dim, bias=True))\n",
        "\n",
        "    self.layernorm_1 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n",
        "    self.layernorm_2 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n",
        "    self.dropout_1 = nn.Dropout(p=dropout)\n",
        "    self.dropout_2 = nn.Dropout(p=dropout)\n",
        "\n",
        "  def forward(self, query, key, value):\n",
        "    attn_output, _ = self.attn(query, key, value)\n",
        "    attn_output = self.dropout_1(attn_output)\n",
        "    out_1 = self.layernorm_1(query+attn_output)\n",
        "    ffn_output = self.ffn(out_1)\n",
        "    ffn_output = self.dropout_2(ffn_output)\n",
        "    out_2 = self.layernorm_2(out_1+ffn_output)\n",
        "    return out_2"
      ],
      "metadata": {
        "id": "AsYlTXuHQNzY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "  def __init__(self, src_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout=0.1, device='cpu'):\n",
        "    super().__init__()\n",
        "    self.embedding = TokenAndPositionEmbedding(src_vocab_size, embed_dim, max_length, device)\n",
        "    self.layers = nn.ModuleList([TransformerEncoderBlock(embed_dim, num_heads, ff_dim, dropout) for i in range(num_layers)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.embedding(x)\n",
        "    for layer in self.layers:\n",
        "      output = layer(output, output, output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "kIs6kdf-Z78c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Decoder"
      ],
      "metadata": {
        "id": "6tTRXsgrRrQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoderBlock(nn.Module):\n",
        "  def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.attn = nn.MultiheadAttention(\n",
        "        embed_dim=embed_dim,\n",
        "        num_heads=num_heads,\n",
        "        batch_first=True)\n",
        "\n",
        "    self.cross_attn = nn.MultiheadAttention(\n",
        "        embed_dim=embed_dim,\n",
        "        num_heads=num_heads,\n",
        "        batch_first=True)\n",
        "\n",
        "    self.ffn = nn.Sequential(\n",
        "        nn.Linear(in_features=embed_dim, out_features=ff_dim, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=ff_dim, out_features=embed_dim, bias=True))\n",
        "\n",
        "    self.layernorm_1 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n",
        "    self.layernorm_2 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n",
        "    self.layernorm_3 = nn.LayerNorm(normalized_shape=embed_dim, eps=1e-6)\n",
        "    self.dropout_1 = nn.Dropout(p=dropout)\n",
        "    self.dropout_2 = nn.Dropout(p=dropout)\n",
        "    self.dropout_3 = nn.Dropout(p=dropout)\n",
        "\n",
        "  def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "    attn_output, _ = self.attn(x, x, x, attn_mask=tgt_mask)\n",
        "    attn_output = self.dropout_1(attn_output)\n",
        "    out_1 = self.layernorm_1(x+attn_output)\n",
        "\n",
        "    attn_output, _ = self.cross_attn(out_1, enc_output, enc_output, attn_mask=src_mask)\n",
        "    attn_output = self.dropout_2(attn_output)\n",
        "    out_2 = self.layernorm_2(out_1+attn_output)\n",
        "\n",
        "    ffn_output = self.ffn(out_2)\n",
        "    ffn_output = self.dropout_3(ffn_output)\n",
        "    out_3 = self.layernorm_3(out_2+ffn_output)\n",
        "    return out_3"
      ],
      "metadata": {
        "id": "HwMGKZQcQN2b"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "  def __init__(self, tgt_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout=0.1, device='cpu'):\n",
        "    super().__init__()\n",
        "    self.embedding = TokenAndPositionEmbedding(tgt_vocab_size, embed_dim, max_length, device)\n",
        "    self.layers = nn.ModuleList([TransformerDecoderBlock(embed_dim, num_heads, ff_dim, dropout) for i in range(num_layers)])\n",
        "\n",
        "  def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "    output = self.embedding(x)\n",
        "    for layer in self.layers:\n",
        "      output = layer(output, enc_output, src_mask, tgt_mask)\n",
        "      return output"
      ],
      "metadata": {
        "id": "6BKdtGYmcMYd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Transformer"
      ],
      "metadata": {
        "id": "eWXlRF5mRze-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, src_vocab_size, tgt_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout=0.1, device='cpu'):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "    self.encoder = TransformerEncoder(src_vocab_size,  embed_dim, max_length, num_layers, num_heads, ff_dim)\n",
        "    self.decoder = TransformerDecoder(tgt_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim)\n",
        "    self.fc = nn.Linear(embed_dim, tgt_vocab_size)\n",
        "\n",
        "  def generate_mask(self, src, tgt):\n",
        "    src_seq_len = src.shape[1]\n",
        "    tgt_seq_len = tgt.shape[1]\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len ), device=self.device).type(torch.bool)\n",
        "    tgt_mask = (torch.triu(torch.ones((tgt_seq_len, tgt_seq_len), device=self.device))==1).transpose(0, 1)\n",
        "    tgt_mask = tgt_mask.float().masked_fill(tgt_mask==0, float('-inf')).masked_fill(tgt_mask==1, float(0.0))\n",
        "    return src_mask, tgt_mask\n",
        "\n",
        "  def forward(self, src, tgt):\n",
        "    src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
        "    enc_output = self.encoder(src)\n",
        "    dec_output = self.decoder(tgt, enc_output, src_mask, tgt_mask)\n",
        "    output = self.fc(dec_output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "x_tT9YT0QN48"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Thử nghiệm"
      ],
      "metadata": {
        "id": "bfppWSWZR6L2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "src_vocab_size = 1000\n",
        "tgt_vocab_size = 2000\n",
        "embed_dim = 200\n",
        "max_length = 100\n",
        "num_layers = 2\n",
        "num_heads = 4\n",
        "ff_dim = 256\n",
        "\n",
        "model = Transformer(src_vocab_size, tgt_vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim)\n",
        "\n",
        "src = torch.randint(high=2, size=(batch_size, max_length), dtype=torch.int64)\n",
        "\n",
        "tgt = torch.randint(high=2, size=(batch_size, max_length), dtype=torch.int64)\n",
        "\n",
        "prediction = model (src, tgt)\n",
        "prediction.shape # batch_size x max_length x tgt_vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxM_9wZMQN8D",
        "outputId": "2e68b6e3-da86-4b76-c63a-5202ff5858ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 100, 2000])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2. Text Classification"
      ],
      "metadata": {
        "id": "skUa4GvBSBlF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Load Dataset"
      ],
      "metadata": {
        "id": "gBcLt7CdSGCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHltuGeaQN_d",
        "outputId": "4128ad35-831f-4a38-faf9-41e5180a8b1a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "ds = load_dataset('thainq107/ntc-scv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLwoMCIwfFS0",
        "outputId": "5828eeaa-d759-4c70-ccb7-cc48c19544a4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Preprocessing\n",
        "Áp dụng hàm tiền xử lý sau trên cột ‘sentence’ hoặc có thể bỏ qua bước tiền xử lý khi áp dụng trên cột ‘preprocessed_sentence’"
      ],
      "metadata": {
        "id": "QfVQGTjISKIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "def preprocess_text(text):\n",
        "  # remove URLs https :// www.url_pattern = re. compile (r’https ?://\\ s+\\ wwww \\.\\s+’)\n",
        "  text = url_pattern.sub(r\" \",text)\n",
        "\n",
        "  # remove HTML Tags : <>\n",
        "  html_pattern = re.compile(r'<[^<>]+>')\n",
        "  text = html_pattern.sub(\" \", text)\n",
        "\n",
        "  # remove puncs and digits\n",
        "  replace_chars = list(string.punctuation + string.digits)\n",
        "\n",
        "  for char in replace_chars:\n",
        "    text = text.replace(char, \" \")\n",
        "\n",
        "  # remove emoji\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "                              u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
        "                              u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
        "                              u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
        "                              u\"\\U0001F1E0-\\U0001F1FF\" # flags (iOS)\n",
        "                              u\"\\U0001F1F2-\\U0001F1F4\" # Macau flag\n",
        "                              u\"\\U0001F1E6-\\U0001F1FF\" # flags\n",
        "                              u\"\\U0001F600-\\U0001F64F\"\n",
        "                              u\"\\U00002702-\\U000027B0\"\n",
        "                              u\"\\U000024C2-\\U0001F251\"\n",
        "                              u\"\\U0001f926-\\U0001f937\"\n",
        "                              u\"\\U0001F1F2\"\n",
        "                              u\"\\U0001F1F4\"\n",
        "                              u\"\\U0001F620\"\n",
        "                              u\"\\u200d\"\n",
        "                              u\"\\u2640-\\u2642\"\n",
        "                              \"]+\", flags=re.UNICODE)\n",
        "  text = emoji_pattern.sub(r\" \", text)\n",
        "\n",
        "  # normalize whitespace\n",
        "  text = \" \".join(text.split())\n",
        "\n",
        "  # lowercasing\n",
        "  text = text.lower()\n",
        "  return text"
      ],
      "metadata": {
        "id": "W3BnJY18QOAX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Representation"
      ],
      "metadata": {
        "id": "bqADAESmSrJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#( install before import torch )\n",
        "# Reinstall torchtext with the correct version for your PyTorch installation.\n",
        "!pip uninstall -y torchtext\n",
        "#!pip install torchtext==0.17.2 torchdata==0.6.1 --no-cache-dir\n",
        "#!pip install torchtext torchdata --no-cache-dir\n",
        "!pip install torchtext==0.17.2 torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQS1wz3qKMFa",
        "outputId": "354ca6fd-4721-48bd-c059-44bab7bcb4e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchtext 0.17.2\n",
            "Uninstalling torchtext-0.17.2:\n",
            "  Successfully uninstalled torchtext-0.17.2\n",
            "Collecting torchtext==0.17.2\n",
            "  Using cached torchtext-0.17.2-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.17.2) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.17.2) (2.32.3)\n",
            "Requirement already satisfied: torch==2.2.2 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.17.2) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.17.2) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->torchtext==0.17.2) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->torchtext==0.17.2) (12.4.127)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.17.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.17.2) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.17.2) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.2->torchtext==0.17.2) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2->torchtext==0.17.2) (1.3.0)\n",
            "Using cached torchtext-0.17.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "Installing collected packages: torchtext\n",
            "Successfully installed torchtext-0.17.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_tokens(sentences, tokenizer):\n",
        "  for sentence in sentences:\n",
        "    yield tokenizer(sentence)\n",
        "\n",
        "# word - based tokenizer\n",
        "from torchtext.data import get_tokenizer\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "# build vocabulary\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "vocab_size = 10000\n",
        "vocabulary = build_vocab_from_iterator(\n",
        "    yield_tokens(ds['train']['preprocessed_sentence'], tokenizer),\n",
        "    max_tokens=vocab_size,\n",
        "    specials=[\"<pad>\", \"<unk>\"])\n",
        "\n",
        "vocabulary.set_default_index(vocabulary[\"<unk>\"])\n",
        "\n",
        "# convert torchtext dataset\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "def prepare_dataset(df):\n",
        "  # create iterator for dataset: (sentence, label)\n",
        "  for row in df:\n",
        "    sentence = row['preprocessed_sentence']\n",
        "    encoded_sentence = vocabulary(tokenizer(sentence))\n",
        "    label = row['label']\n",
        "    yield encoded_sentence, label\n",
        "\n",
        "train_dataset = prepare_dataset(ds['train'])\n",
        "train_dataset = to_map_style_dataset(train_dataset)\n",
        "\n",
        "valid_dataset = prepare_dataset(ds['valid'])\n",
        "valid_dataset = to_map_style_dataset(valid_dataset)\n",
        "\n",
        "test_dataset = prepare_dataset(ds['test'])\n",
        "test_dataset = to_map_style_dataset(test_dataset)\n"
      ],
      "metadata": {
        "id": "AmpVeYvBQOH5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Dataloader"
      ],
      "metadata": {
        "id": "HEnaSaEKS1n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "seq_length = 100\n",
        "\n",
        "def collate_batch(batch):\n",
        "  # create inputs , offsets , labels for batch\n",
        "  sentences, labels = list(zip(*batch))\n",
        "  encoded_sentences = [sentence+([0]*(seq_length-len(sentence))) if len(sentence)<seq_length else sentence[:seq_length] for sentence in sentences]\n",
        "\n",
        "  encoded_sentences = torch.tensor(encoded_sentences, dtype=torch.int64)\n",
        "  labels = torch.tensor(labels)\n",
        "  return encoded_sentences, labels\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True,\n",
        "                              collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(valid_dataset,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=False,\n",
        "                              collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_dataset,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=False,\n",
        "                             collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "ooqnkz4BQOLH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Trainer"
      ],
      "metadata": {
        "id": "1sO56e-ES7rJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train epoch\n",
        "import time\n",
        "\n",
        "def train_epoch(model, optimizer, criterion, train_dataloader, device, epoch=0, log_interval=50):\n",
        "  model.train()\n",
        "  total_acc, total_count = 0, 0\n",
        "  losses = []\n",
        "  start_time = time.time()\n",
        "\n",
        "  for idx, (inputs, labels ) in enumerate(train_dataloader):\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    predictions = model(inputs)\n",
        "\n",
        "    # compute loss\n",
        "    loss = criterion(predictions, labels)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # backward\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_acc += (predictions.argmax(1) == labels).sum().item()\n",
        "    total_count += labels.size(0)\n",
        "    if idx % log_interval == 0 and idx > 0:\n",
        "      elapsed = time.time() - start_time\n",
        "      print(\n",
        "          \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
        "          \"| accuracy {:8.3f}\".format(epoch, idx, len(train_dataloader), total_acc/total_count))\n",
        "\n",
        "      total_acc, total_count = 0, 0\n",
        "      start_time = time.time()\n",
        "\n",
        "  epoch_acc = total_acc/total_count\n",
        "  epoch_loss = sum(losses)/len(losses)\n",
        "  return epoch_acc , epoch_loss"
      ],
      "metadata": {
        "id": "Nz5PrH7OUy_V"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate\n",
        "def evaluate_epoch(model, criterion, valid_dataloader, device):\n",
        "  model.eval()\n",
        "  total_acc, total_count = 0, 0\n",
        "  losses = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for idx, (inputs, labels) in enumerate(valid_dataloader):\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      predictions = model(inputs)\n",
        "\n",
        "      loss = criterion(predictions, labels)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "      total_acc += (predictions.argmax(1) == labels).sum().item()\n",
        "      total_count += labels.size(0)\n",
        "\n",
        "  epoch_acc = total_acc/total_count\n",
        "  epoch_loss = sum(losses)/len(losses)\n",
        "  return epoch_acc, epoch_loss\n"
      ],
      "metadata": {
        "id": "cvZII_tNWAw-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "def train(model, model_name, save_model, optimizer, criterion, train_dataloader, valid_dataloader, num_epochs, device):\n",
        "  train_accs, train_losses = [], []\n",
        "  eval_accs, eval_losses = [], []\n",
        "  best_loss_eval = 100\n",
        "  times = []\n",
        "  for epoch in range(1, num_epochs+1):\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    # Training\n",
        "    train_acc, train_loss = train_epoch(model, optimizer, criterion, train_dataloader, device, epoch)\n",
        "    train_accs.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Evaluation\n",
        "    eval_acc, eval_loss = evaluate_epoch(model, criterion, valid_dataloader, device)\n",
        "    eval_accs.append(eval_acc)\n",
        "    eval_losses.append(eval_loss)\n",
        "\n",
        "    # Save best model\n",
        "    if eval_loss < best_loss_eval:\n",
        "      torch.save(model.state_dict(), save_model + f'/{model_name}.pt')\n",
        "\n",
        "    times.append(time.time() - epoch_start_time)\n",
        "\n",
        "    # Print loss, acc end epoch\n",
        "    print(\"-\" * 59)\n",
        "    print(\"| End of epoch {:3d} | Time: {:5.2f}s | Train Accuracy {:8.3f} | Train Loss {:8.3f}\"\n",
        "          \"| Valid Accuracy {:8.3f} | Valid Loss {:8.3f}\".format(epoch, time.time() - epoch_start_time, train_acc, train_loss, eval_acc, eval_loss))\n",
        "    print(\"-\" * 59)\n",
        "\n",
        "    # Load best model\n",
        "    model.load_state_dict(torch.load(save_model + f'/{model_name}.pt'))\n",
        "    model.eval()\n",
        "    metrics = {'train_accuracy':train_accs, 'train_loss':train_losses, 'valid_accuracy':eval_accs, 'valid_loss':eval_losses, 'time':times}\n",
        "\n",
        "    return model, metrics"
      ],
      "metadata": {
        "id": "Unvc2r6CX4MP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# report\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_result(num_epochs, train_accs, eval_accs, train_losses, eval_losses):\n",
        "  epochs = list(range(num_epochs))\n",
        "  fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
        "  axs[0].plot(epochs, train_accs, label=\"Training\")\n",
        "  axs[0].plot(epochs, eval_accs, label=\"Evaluation\")\n",
        "  axs[1].plot(epochs, train_losses, label=\"Training\")\n",
        "  axs[1].plot(epochs, eval_losses, label=\"Evaluation\")\n",
        "  axs[0].set_xlabel(\"Epochs\")\n",
        "  axs[1].set_xlabel(\"Epochs\")\n",
        "  axs[0].set_ylabel(\"Accuracy\")\n",
        "  axs[1].set_ylabel(\"Loss\")\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "ZcA15QhkQOOJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.Modeling"
      ],
      "metadata": {
        "id": "W3k7lN-kTMaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderCls(nn.Module):\n",
        "  def __init__(self, vocab_size, max_length, num_layers, embed_dim, num_heads, ff_dim, dropout=0.1, device='cpu'):\n",
        "    super().__init__()\n",
        "    self.encoder = TransformerEncoder(vocab_size, embed_dim, max_length, num_layers, num_heads, ff_dim, dropout, device)\n",
        "    self.pooling = nn.AvgPool1d(kernel_size=max_length)\n",
        "    self.fc1 = nn.Linear(in_features=embed_dim, out_features=20)\n",
        "    self.fc2 = nn.Linear(in_features=20, out_features=2)\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.encoder(x)\n",
        "    output = self.pooling(output.permute(0, 2, 1)).squeeze()\n",
        "    output = self.dropout(output)\n",
        "    output = self.fc1(output)\n",
        "    output = self.dropout(output)\n",
        "    output = self.fc2(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "fzI-fRcmQOTl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.Training"
      ],
      "metadata": {
        "id": "SoAhyOIpTSGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os # Import the os module\n",
        "import torch.optim as optim\n",
        "\n",
        "vocab_size = 10000\n",
        "max_length = 100\n",
        "embed_dim = 200\n",
        "num_layers = 2\n",
        "num_heads = 4\n",
        "ff_dim = 128\n",
        "dropout =0.1\n",
        "\n",
        "model = TransformerEncoderCls(vocab_size, max_length, num_layers, embed_dim, num_heads, ff_dim, dropout)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = TransformerEncoderCls(vocab_size, max_length, num_layers, embed_dim, num_heads, ff_dim, dropout, device)\n",
        "model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
        "\n",
        "num_epochs = 50\n",
        "save_model = './model'\n",
        "os.makedirs(save_model, exist_ok=True)\n",
        "model_name = 'model'\n",
        "\n",
        "model, metrics = train(model, model_name, save_model, optimizer, criterion, train_dataloader, valid_dataloader, num_epochs, device)"
      ],
      "metadata": {
        "id": "Kg_TC6UaQOXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0821e916-f287-4e09-b269-5bd882db4d19"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |    50/  235 batches | accuracy    0.539\n",
            "| epoch   1 |   100/  235 batches | accuracy    0.582\n",
            "| epoch   1 |   150/  235 batches | accuracy    0.672\n",
            "| epoch   1 |   200/  235 batches | accuracy    0.715\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   1 | Time: 328.13s | Train Accuracy    0.743 | Train Loss    0.643| Valid Accuracy    0.755 | Valid Loss    0.523\n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_accs, train_losses, eval_accs, eval_losses, times = metrics['train_accuracy'], metrics['train_loss'], metrics['valid_accuracy'], metrics['valid_loss'], metrics['time']"
      ],
      "metadata": {
        "id": "09PAvJLzc2sg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_accs, train_losses, eval_accs, eval_losses, times"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEQ66bQ0dZv-",
        "outputId": "fbeeb1c5-852a-4f1a-8384-c69c9b98ac07"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.7434456928838952],\n",
              " [0.6431318794159179],\n",
              " [0.7547],\n",
              " [0.5234171868879584],\n",
              " [328.130752325058])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot_result(num_epochs, train_accs, eval_accs, train_losses, eval_losses)"
      ],
      "metadata": {
        "id": "-ncDcPwocSVB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phần 2. Text Classification using BERT\n",
        "Một trong những mô hình pretrained đầu tiên cho dữ liệu văn bản dựa vào kiến trúc mô hình Transformer được ứng dụng cho các downstream task khác nhau đó là BERT. Trong phần này chúng ta sẽ fine tuning BERT cho bài toán phân loại trên bộ dữ liệu NTC-SCV dựa vào thư viện transformers của huggingface."
      ],
      "metadata": {
        "id": "KilETP24TkhW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Load Dataset"
      ],
      "metadata": {
        "id": "-F2q7XI6T0dM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install libs\n",
        "!pip install -q -U transformers datasets accelerate evaluate\n"
      ],
      "metadata": {
        "id": "lhfaz53gQOZs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "ds = load_dataset('thainq107/ntc-scv')"
      ],
      "metadata": {
        "id": "vyrvcpX3liDq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Preprocessing"
      ],
      "metadata": {
        "id": "GRj9jAaaT87e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization\n",
        "from transformers import AutoTokenizer\n",
        "model_name = \"distilbert-base-uncased\" # bert-base-uncased\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "max_seq_length = 100\n",
        "max_seq_length = min(max_seq_length, tokenizer.model_max_length)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "  # Tokenize the texts\n",
        "  result = tokenizer(\n",
        "      examples[\"preprocessed_sentence\"],\n",
        "      padding=\"max_length\",\n",
        "      max_length=max_seq_length,\n",
        "      truncation=True)\n",
        "\n",
        "  result[\"label\"] = examples['label']\n",
        "  return result\n",
        "\n",
        "# Running the preprocessing pipeline on all the datasets\n",
        "processed_dataset = ds.map(preprocess_function, batched=True, desc=\"Running tokenizer on dataset\",)"
      ],
      "metadata": {
        "id": "WJaz7pBvQOc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Modeling"
      ],
      "metadata": {
        "id": "M2gA913qUF2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nojkpMxYkNn9",
        "outputId": "5124fa52-d2fb-49a2-b401-d18c91a12180"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
        "\n",
        "num_labels = 2\n",
        "\n",
        "config = AutoConfig.from_pretrained(model_name, num_labels=num_labels, finetuning_task=\"text-classification\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)"
      ],
      "metadata": {
        "id": "JNLhxi2lQOgK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "b7cb5e90f1064e65a9acadb3342c36a7",
            "97085b06fc784acab5a3b446d9876326",
            "0303ea5d59a7478c95317653224eccd2",
            "8e276915b185416c86807f613422191a",
            "da815355fd5c4a22bbd492e14db8dca4",
            "54982841d9cd4407bfe8538aad37b25e",
            "93a4d3ab1a06433f8569c09ffd338db3",
            "35863770a03948619de1cebd7ea483bc",
            "ac428d8b68a94bdcb9c7cfdd5109cd67",
            "929964ab7e3e4845838662d09e0346b3",
            "ddb70ed778594d9a93d83805bee8cd2c"
          ]
        },
        "outputId": "9c6486f4-b018-4892-9f54-05a6f8860b4c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7cb5e90f1064e65a9acadb3342c36a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Metric"
      ],
      "metadata": {
        "id": "g6Gz39oAUKOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "  predictions, labels = eval_pred\n",
        "  predictions = np.argmax(predictions, axis=1)\n",
        "  result = metric.compute(predictions=predictions, references=labels)\n",
        "  return result"
      ],
      "metadata": {
        "id": "7IcC8x8MQOi8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "477813d3da8e45c5a2514230bf955752",
            "657ea2845d624514a2acff5efb9d516d",
            "1c8fef96716e4d7eb492291da4cb2a04",
            "bd5d4cdc170240f09f38e8470701b2c4",
            "24b022b8a25d4c55aaf7b9822ef27f6e",
            "109fb11dd61f417eb3e5abd220b38f4f",
            "2b8e9f73847a4f61abcd9dd2bca7269a",
            "190b242c08dc4e45830af30b2ef2c80c",
            "bcef230c45054ba6aaa444703037b770",
            "fed5a54412fb457db25405d32293fc93",
            "adbab2ade3e44465afed6e370dc12707"
          ]
        },
        "outputId": "cb407769-1001-4cd7-98d8-ba4addae365d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "477813d3da8e45c5a2514230bf955752"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Trainer"
      ],
      "metadata": {
        "id": "s80z9dhtUPVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "training_args = TrainingArguments(output_dir=\"save_model\",\n",
        "                                  learning_rate=2e-5,\n",
        "                                  per_device_train_batch_size=128,\n",
        "                                  per_device_eval_batch_size=128,\n",
        "                                  num_train_epochs=10,\n",
        "                                  eval_strategy=\"epoch\",\n",
        "                                  save_strategy=\"epoch\",\n",
        "                                  load_best_model_at_end=True)\n",
        "trainer = Trainer(model=model,\n",
        "                  args=training_args,\n",
        "                  train_dataset=processed_dataset[\"train\"],\n",
        "                  eval_dataset=processed_dataset[\"valid\"],\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  tokenizer=tokenizer,)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "CQX2r6nGQOl8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "c0dbc245-f738-47e7-bf23-d1db48c943fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-431ce619b201>:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(model=model,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.Training"
      ],
      "metadata": {
        "id": "A8rnylafUVzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phần 3. Vision Transformer"
      ],
      "metadata": {
        "id": "BFyeiHjWUonu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Load Dataset"
      ],
      "metadata": {
        "id": "SbHpYHYAUwU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision . transforms as transforms\n",
        "from torch . utils . data import DataLoader , random_split\n",
        "import torch . optim as optim\n",
        "from torchvision . datasets import ImageFolder\n",
        "from torch import nn\n",
        "import math\n",
        "import os\n",
        "# download\n",
        "! gdown 1 vSevps_hV5zhVf6aWuN8X7dd - qSAIgcc\n",
        "! unzip ./ flower_photos .zip\n",
        "# load data\n",
        "data_patch = \"./ flower_photos \"\n",
        "dataset = ImageFolder ( root = data_patch )\n",
        "num_samples = len( dataset )\n",
        "classes = dataset . classes\n",
        "num_classes = len( dataset . classes )\n",
        "# split\n",
        "TRAIN_RATIO , VALID_RATIO = 0.8 , 0.1\n",
        "n_train_examples = int( num_samples * TRAIN_RATIO )\n",
        "n_valid_examples = int( num_samples * VALID_RATIO )\n",
        "n_test_examples = num_samples - n_train_examples - n_valid_examples\n",
        "train_dataset , valid_dataset , test_dataset = random_split (\n",
        "dataset ,\n",
        "[ n_train_examples , n_valid_examples , n_test_examples ]\n",
        ")"
      ],
      "metadata": {
        "id": "KLqSVO5pQOo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Preprocessing"
      ],
      "metadata": {
        "id": "mgXwmgJGU11a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# resize + convert to tensor\n",
        "IMG_SIZE = 224\n",
        "train_transforms = transforms . Compose ([\n",
        "transforms . Resize (( IMG_SIZE , IMG_SIZE )),\n",
        "transforms . RandomHorizontalFlip () ,\n",
        "transforms . RandomRotation (0.2) ,\n",
        "transforms . ToTensor () ,\n",
        "transforms . Normalize ([0.5 , 0.5 , 0.5] , [0.5 , 0.5 , 0.5])\n",
        "])\n",
        "test_transforms = transforms . Compose ([\n",
        "transforms . Resize (( IMG_SIZE , IMG_SIZE )),\n",
        "transforms . ToTensor () ,\n",
        "transforms . Normalize ([0.5 , 0.5 , 0.5] , [0.5 , 0.5 , 0.5])\n",
        "])\n",
        "# apply\n",
        "train_dataset . dataset . transform = train_transforms\n",
        "valid_dataset . dataset . transform = test_transforms\n",
        "test_dataset . dataset . transform = test_transforms"
      ],
      "metadata": {
        "id": "Xo32njWoQOsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Dataloader"
      ],
      "metadata": {
        "id": "4Abl_uKWVCDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 512\n",
        "train_loader = DataLoader (\n",
        "train_dataset ,\n",
        "shuffle =True ,\n",
        "batch_size = BATCH_SIZE\n",
        ")\n",
        "val_loader = DataLoader (\n",
        "valid_dataset ,\n",
        "batch_size = BATCH_SIZE\n",
        ")\n",
        "test_loader = DataLoader (\n",
        "test_dataset ,\n",
        "batch_size = BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "id": "r2hR7uJmQOvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Training from Scratch"
      ],
      "metadata": {
        "id": "zcaU2-0cVIQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1. Modeling"
      ],
      "metadata": {
        "id": "YnsANZwRVNBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder (nn. Module ):\n",
        "def __init__ (self , embed_dim , num_heads , ff_dim , dropout =0.1) :\n",
        "super (). __init__ ()\n",
        "self . attn = nn. MultiheadAttention (\n",
        "embed_dim = embed_dim ,\n",
        "num_heads = num_heads ,\n",
        "batch_first = True\n",
        ")\n",
        "self . ffn = nn. Sequential (\n",
        "nn. Linear ( in_features = embed_dim , out_features =ff_dim , bias = True ),\n",
        "nn. ReLU () ,\n",
        "nn. Linear ( in_features =ff_dim , out_features = embed_dim , bias = True )\n",
        ")\n",
        "self . layernorm_1 = nn. LayerNorm ( normalized_shape = embed_dim , eps =1e -6)\n",
        "self . layernorm_2 = nn. LayerNorm ( normalized_shape = embed_dim , eps =1e -6)\n",
        "self . dropout_1 = nn. Dropout (p= dropout )\n",
        "self . dropout_2 = nn. Dropout (p= dropout )\n",
        "def forward (self , query , key , value ):\n",
        "attn_output , _ = self . attn (query , key , value )\n",
        "attn_output = self . dropout_1 ( attn_output )\n",
        "out_1 = self . layernorm_1 ( query + attn_output )\n",
        "ffn_output = self .ffn( out_1 )\n",
        "ffn_output = self . dropout_2 ( ffn_output )\n",
        "out_2 = self . layernorm_2 ( out_1 + ffn_output )\n",
        "return out_2"
      ],
      "metadata": {
        "id": "AI8pi8nvQOyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchPositionEmbedding (nn. Module ):\n",
        "def __init__ (self , image_size =224 , embed_dim =512 , patch_size =16 , device =’cpu ’):\n",
        "super (). __init__ ()\n",
        "self . conv1 = nn. Conv2d ( in_channels =3, out_channels = embed_dim , kernel_size =\n",
        "patch_size , stride = patch_size , bias = False )\n",
        "scale = embed_dim ** -0.5\n",
        "self . positional_embedding = nn. Parameter ( scale * torch . randn (( image_size //\n",
        "patch_size ) ** 2, embed_dim ))\n",
        "self . device = device\n",
        "def forward (self , x):\n",
        "x = self . conv1 (x) # shape = [*, width , grid , grid ]\n",
        "x = x. reshape (x. shape [0] , x. shape [1] , -1) # shape = [*, width , grid ** 2]\n",
        "x = x. permute (0, 2, 1) # shape = [*, grid ** 2, width ]\n",
        "x = x + self . positional_embedding .to( self . device )\n",
        "return x"
      ],
      "metadata": {
        "id": "fC7T0Dp4QO1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VisionTransformerCls (nn. Module ):\n",
        "def __init__ (self ,\n",
        "image_size , embed_dim , num_heads , ff_dim ,\n",
        "dropout =0.1 , device =’cpu ’, num_classes = 10, patch_size =16\n",
        "):\n",
        "super (). __init__ ()\n",
        "self . embd_layer = PatchPositionEmbedding (\n",
        "image_size = image_size , embed_dim = embed_dim , patch_size = patch_size , device =\n",
        "device\n",
        ")\n",
        "self . transformer_layer = TransformerEncoder (\n",
        "embed_dim , num_heads , ff_dim , dropout\n",
        ")\n",
        "# self . pooling = nn. AvgPool1d ( kernel_size = max_length )\n",
        "self . fc1 = nn. Linear ( in_features = embed_dim , out_features =20)\n",
        "self . fc2 = nn. Linear ( in_features =20 , out_features = num_classes )\n",
        "self . dropout = nn. Dropout (p= dropout )\n",
        "self . relu = nn. ReLU ()\n",
        "def forward (self , x):\n",
        "output = self . embd_layer (x)\n",
        "output = self . transformer_layer (output , output , output )\n",
        "output = output [:, 0, :]\n",
        "output = self . dropout ( output )\n",
        "output = self .fc1( output )\n",
        "output = self . dropout ( output )\n",
        "output = self .fc2( output )\n",
        "return output"
      ],
      "metadata": {
        "id": "HwtMFBSgQO4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2. Training"
      ],
      "metadata": {
        "id": "xvR7aQpfWAbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size =224\n",
        "embed_dim = 512\n",
        "num_heads = 4\n",
        "ff_dim = 128\n",
        "dropout =0.1\n",
        "device = torch . device (’cuda ’ if torch . cuda . is_available () else ’cpu ’)\n",
        "model = VisionTransformerCls (\n",
        "image_size =224 , embed_dim =512 , num_heads = num_heads , ff_dim =ff_dim , dropout = dropout\n",
        ", num_classes = num_classes , device = device\n",
        ")\n",
        "model .to( device )\n",
        "criterion = torch .nn. CrossEntropyLoss ()\n",
        "optimizer = optim . Adam ( model . parameters () , lr =0.0005)\n",
        "num_epochs = 100\n",
        "save_model = ‘./ vit_flowers ’\n",
        "os. makedirs ( save_model , exist_ok = True )\n",
        "model_name = ‘vit_flowers ’\n",
        "model , metrics = train (\n",
        "model , model_name , save_model , optimizer , criterion , train_loader , val_loader ,\n",
        "num_epochs , device\n",
        ")"
      ],
      "metadata": {
        "id": "nxaghz2eQO-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Fine Tuning"
      ],
      "metadata": {
        "id": "1nB2yggJWGiZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1. Modeling"
      ],
      "metadata": {
        "id": "40lYQ3FYWJN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTForImageClassification\n",
        "id2label = {id: label for id , label in enumerate ( classes )}\n",
        "label2id = { label :id for id , label in id2label . items ()}\n",
        "model = ViTForImageClassification . from_pretrained (’google /vit -base - patch16 -224 - in21k ’,\n",
        "num_labels = num_classes ,\n",
        "id2label = id2label ,\n",
        "label2id = label2id )\n",
        "device = torch . device (’cuda ’ if torch . cuda . is_available () else ’cpu ’)\n",
        "model .to( device )"
      ],
      "metadata": {
        "id": "7ioMJlTBQPCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2. Metric"
      ],
      "metadata": {
        "id": "xRyuLsXVWOUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "metric = evaluate . load (\" accuracy \")\n",
        "def compute_metrics ( eval_pred ):\n",
        "predictions , labels = eval_pred\n",
        "predictions = np. argmax ( predictions , axis =1)\n",
        "return metric . compute ( predictions = predictions , references = labels )"
      ],
      "metadata": {
        "id": "q4hwTN-JQPFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3. Trainer"
      ],
      "metadata": {
        "id": "3utafYdeWRyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import ViTImageProcessor\n",
        "from transformers import TrainingArguments , Trainer\n",
        "feature_extractor = ViTImageProcessor . from_pretrained (\" google /vit -base - patch16 -224 -\n",
        "in21k \")\n",
        "metric_name = \" accuracy \"\n",
        "args = TrainingArguments (\n",
        "f\" vit_flowers \",\n",
        "save_strategy =\" epoch \",\n",
        "evaluation_strategy =\" epoch \",\n",
        "learning_rate =2e -5,\n",
        "per_device_train_batch_size =32 ,\n",
        "per_device_eval_batch_size =32 ,\n",
        "num_train_epochs =10 ,\n",
        "weight_decay =0.01 ,\n",
        "load_best_model_at_end =True ,\n",
        "metric_for_best_model = metric_name ,\n",
        "logging_dir =’logs ’,\n",
        "remove_unused_columns =False ,\n",
        ")\n",
        "def collate_fn ( examples ):\n",
        "# example => Tuple (image , label )\n",
        "pixel_values = torch . stack ([ example [0] for example in examples ])\n",
        "labels = torch . tensor ([ example [1] for example in examples ])\n",
        "return {\" pixel_values \": pixel_values , \" labels \": labels }"
      ],
      "metadata": {
        "id": "B5_zkzbKQPIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer (\n",
        "model ,\n",
        "args ,\n",
        "train_dataset = train_dataset ,\n",
        "eval_dataset = valid_dataset ,\n",
        "data_collator = collate_fn ,\n",
        "compute_metrics = compute_metrics ,\n",
        "tokenizer = feature_extractor ,\n",
        ")"
      ],
      "metadata": {
        "id": "uJ08pVlQQPL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4. Training"
      ],
      "metadata": {
        "id": "SHbQWHx_WY8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer . train ()\n",
        "outputs = trainer . predict ( test_dataset )\n",
        "outputs . metrics"
      ],
      "metadata": {
        "id": "jrr0b0NTQPO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C0uqZx1lQPSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YYrogYWTQPVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BvtrqSo6QPYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tmU-4TLMQPbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wSdz3N2tQPem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AfBL2jXwQPgx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}